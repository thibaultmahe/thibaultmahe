{
  "active": false,
  "connections": {
    "On new manual Chat Message": {
      "main": [
        [
          {
            "node": "Basic LLM Chain",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Hugging Face Inference Model": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    }
  },
  "createdAt": "2023-12-30T10:52:40.318Z",
  "id": "jvuP3HYxRKJZGZJQ",
  "isArchived": false,
  "meta": null,
  "name": "AI hugging Face",
  "nodes": [
    {
      "parameters": {},
      "id": "06d203a0-d752-4150-8eaa-edab65cac291",
      "name": "On new manual Chat Message",
      "type": "@n8n/n8n-nodes-langchain.manualChatTrigger",
      "position": [
        740,
        800
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "model": "mistralai/Mixtral-8x7B-Instruct-v0.1",
        "options": {
          "frequencyPenalty": 2,
          "maxTokens": 512,
          "temperature": 0.8
        }
      },
      "id": "66cd79a2-6e6c-4e5b-a5e2-f91dfd8d5747",
      "name": "Hugging Face Inference Model",
      "type": "@n8n/n8n-nodes-langchain.lmOpenHuggingFaceInference",
      "position": [
        980,
        1000
      ],
      "typeVersion": 1,
      "credentials": {
        "huggingFaceApi": {
          "id": "dzX4lRNoSA7KgEWU",
          "name": "HuggingFaceApi account"
        }
      }
    },
    {
      "parameters": {
        "content": "## This is an example of basic LLM Chain connected to an open-source model\n### The Chain is connected to the Mistral-7B-Instruct-v0.1 model, but you can change this\n\nPlease note the initial prompt that guides the model:\n```\nYou are a helpful assistant.\nPlease reply politely to the users.\nUse emojis and a text.\nQ: {{ $json.input }}\nA: \n```\n\nThis way the model \"knows\" that it needs to answer the question right after the `A: `.\n\nSince Hugging Face node is this is an inference mode, it does not support LangChain Agents at the moment. Please use [Ollama Chat Model](https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatollama/) node for that",
        "height": 317,
        "width": 1083
      },
      "id": "01606dca-d57c-4c96-b14d-dcf6dbcebae2",
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        500,
        440
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "prompt": "=Tu es un assistant français. Tu ne réponds que en Français. Si tu ne sais pas la réponse, tu n'inventes pas, tu dis que tu ne sais pas. Tu dois utiliser des emojis dans ta réponse.\nQ: {{ $json.input }}\nA: "
      },
      "id": "1d821193-7e17-4706-a8bc-71ee9dda1ef4",
      "name": "Basic LLM Chain",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "position": [
        960,
        800
      ],
      "typeVersion": 1
    }
  ],
  "pinData": {},
  "settings": {
    "executionOrder": "v1"
  },
  "shared": [
    {
      "updatedAt": "2023-12-30T10:52:40.318Z",
      "createdAt": "2023-12-30T10:52:40.318Z",
      "role": "workflow:owner",
      "workflowId": "jvuP3HYxRKJZGZJQ",
      "projectId": "8nM2sM0qimdfJmkc"
    }
  ],
  "staticData": null,
  "tags": [],
  "triggerCount": 0,
  "updatedAt": "2024-01-15T14:07:15.876Z",
  "versionId": "14fe23e7-9bd9-41c4-8d4d-e7c7548bc449"
}